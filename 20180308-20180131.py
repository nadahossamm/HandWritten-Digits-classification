# -*- coding: utf-8 -*-
"""Machine 3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WM2nWVPWGI3CrbEUSfGlX141yYaC_QeP
"""

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten,Conv2D ,MaxPooling2D
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split

def resizingImage(x_train,x_test):
    size=28
    x_train=np.array(x_train).reshape(-1,size,size,1)
    x_test=np.array(x_test).reshape(-1,size,size,1)
    return x_train,x_test

def doNormalization(x_train,x_test):
    x_train=x_train.astype('float32')/255
    x_test=x_test.astype('float32')/255
    return x_train,x_test

def CNN_First_Model(x_train):
    model=Sequential()
    model.add(Conv2D(64,(4,4),input_shape=x_train.shape[1:]))     # first conv layer
    model.add(Activation("relu"))  
    model.add(MaxPooling2D(pool_size=(2,2)))    # take max from ( 2 2 ) matrix


    #fully connected layer 1
    model.add(Flatten()) #from 2d to 1d
    model.add(Dense(80))
    model.add(Activation("relu"))

    #last fully connected layer *output lazm yb2a mn 0 l 9*
    model.add(Dense(10))
    model.add(Activation("softmax"))
    return model

def CNN_Second_Model(x_train):
    model=Sequential()
    model.add(Conv2D(64,(3,3),input_shape=x_train.shape[1:]))     # first conv layer
    model.add(Activation("relu"))    
    model.add(MaxPooling2D(pool_size=(3,3)))    # take max from ( 3 3 ) matrix

    # secound conv layer
    model.add(Conv2D(32,(3,3))) 
    model.add(Activation("relu"))
    model.add(MaxPooling2D(pool_size=(2,2)))  # take max from ( 2 2 ) matrix


    #fully connected layer 1
    model.add(Flatten()) #from 2d to 1d
    model.add(Dense(64))
    model.add(Activation("relu"))

    #fully connected layer 2
    model.add(Dense(32))
    model.add(Activation("relu"))

    #last fully connected layer *output lazm yb2a mn 0 l 9*
    model.add(Dense(10))
    model.add(Activation("softmax"))
    return model

def CNN_Third_Model(x_train):
    model=Sequential()
    model.add(Conv2D(64,(3,3),input_shape=x_train.shape[1:]))     # first conv layer
    model.add(Activation("relu"))    
    model.add(MaxPooling2D(pool_size=(2,2)))    # take max from ( 3 3 ) matrix

    # second conv layer
    model.add(Conv2D(32,(2,2))) 
    model.add(Activation("relu"))
    model.add(MaxPooling2D(pool_size=(2,2)))  # take max from ( 2 2 ) matrix

    # thirs conv layer
    model.add(Conv2D(32,(2,2))) 
    model.add(Activation("relu"))
    model.add(MaxPooling2D(pool_size=(2,2)))  # take max from ( 2 2 ) matrix


    #fully connected layer 1
    model.add(Flatten()) #from 2d to 1d
    model.add(Dense(64))
    model.add(Activation("relu"))

    #fully connected layer 2
    model.add(Dense(32))
    model.add(Activation("relu"))

    #fully connected layer 3
    model.add(Dense(16))
    model.add(Activation("relu"))
    
    #last fully connected layer *output lazm yb2a mn 0 l 9*
    model.add(Dense(10))
    model.add(Activation("softmax"))
    return model

def CNN_Fourth_Model(x_train):
    model=Sequential()
    model.add(Conv2D(64,(3,3),input_shape=x_train.shape[1:]))     # first conv layer
    model.add(Activation("relu"))    #make it non linear
    model.add(MaxPooling2D(pool_size=(3,3)))    # take max from ( 3 3 ) matrix

    model.add(Conv2D(64,(3,3),input_shape=x_train.shape[1:]))     # second conv layer
    model.add(Activation("relu"))    #make it non linear
    model.add(MaxPooling2D(pool_size=(2,2)))   # take max from ( 2 2 ) matrix

    

    #fully connected layer 1
    model.add(Flatten()) #from 2d to 1d
    model.add(Dense(64))
    model.add(Activation("relu"))

    #last fully connected layer *output lazm yb2a mn 0 l 9*
    model.add(Dense(10))
    model.add(Activation("softmax"))
    return model

mnist=tf.keras.datasets.mnist
(x_train, y_train), (x_test, y_test) =mnist.load_data()
x_train,x_test=resizingImage(x_train,x_test)
x_train,x_test=doNormalization(x_train,x_test)

#first model
sumAcc=0
for i in range(4):
  sum2val=0
  x_train,vx,y_train,vy=train_test_split(x_train,y_train,test_size=.25)
  model = CNN_First_Mode1(x_train)
  model.compile(loss="sparse_categorical_crossentropy", optimizer="adam", metrics=['accuracy'])
  x=model.fit(x_train, y_train, epochs =5,validation_data=(vx,vy))
  lossTest,accuracyTest = model.evaluate(x_test,y_test)
  print("Accuracy test = ",accuracyTest*100 )
  for j in range(5):
    sum2val+=x.history['val_accuracy'][j]
  sum2val=sum2val/5
  sumAcc+=sum2val

avgValAcc=sumAcc/4
print("Validation Acc = ",avgValAcc*100)

#Second model
sumAcc=0
for i in range(4):
  sum2val=0
  x_train,vx,y_train,vy=train_test_split(x_train,y_train,test_size=.25)
  model = CNN_Second_Model(x_train)
  model.compile(loss="sparse_categorical_crossentropy", optimizer="adam", metrics=['accuracy'])
  x=model.fit(x_train, y_train, epochs =5,validation_data=(vx,vy))
  lossTest,accuracyTest = model.evaluate(x_test,y_test)
  print("Accuracy test = ",accuracyTest*100 )
  for j in range(5):
    sum2val+=x.history['val_accuracy'][j]
  sum2val=sum2val/5
  sumAcc+=sum2val

avgValAcc=sumAcc/4

print("Validation Acc = ",avgValAcc*100)

#third model
sumAcc=0
for i in range(4):
  sum2val=0
  x_train,vx,y_train,vy=train_test_split(x_train,y_train,test_size=.25)
  model = CNN_Third_Model(x_train)
  model.compile(loss="sparse_categorical_crossentropy", optimizer="adam", metrics=['accuracy'])
  x=model.fit(x_train, y_train, epochs =5,validation_data=(vx,vy))
  lossTest,accuracyTest = model.evaluate(x_test,y_test)
  print("Accuracy test= ",accuracyTest*100 )
  for j in range(5):
    sum2val+=x.history['val_accuracy'][j]
  sum2val=sum2val/5
  sumAcc+=sum2val

avgValAcc=sumAcc/4
print("Validation Acc = ",avgValAcc*100)

#Fourth model
sumAcc=0
for i in range(4):
  sum2val=0
  x_train,vx,y_train,vy=train_test_split(x_train,y_train,test_size=.25)
  model = CNN_Fourth_Model(x_train)
  model.compile(loss="sparse_categorical_crossentropy", optimizer="adam", metrics=['accuracy'])
  x=model.fit(x_train, y_train, epochs =5,validation_data=(vx,vy))
  lossTest,accuracyTest = model.evaluate(x_test,y_test)
  print("Accuracy test= ",accuracyTest*100 )
  for j in range(5):
    sum2val+=x.history['val_accuracy'][j]
  sum2val=sum2val/5
  sumAcc+=sum2val

avgValAcc=sumAcc/4
print("Validation Acc = ",avgValAcc*100)

